{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHThY3+MDWOT0OkMwgnLBt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gibsdevops/NLP_with_tensorflow/blob/main/nlp_with_multiple_types_of_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fcJw2EgzwZbc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get the dataset\n",
        "\n",
        "dataset, info = tfds.load('glue/sst2', with_info=True)\n",
        "print(info.features)"
      ],
      "metadata": {
        "id": "d8aCnv-eKKmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(info.features['label'].num_classes)\n",
        "print(info.features['label'].names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inzf2BKUKqBB",
        "outputId": "35e43adf-289b-4895-d88c-f627104d8068"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "['negative', 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get the training and the validation datasets\n",
        "\n",
        "dataset_train = dataset['train']\n",
        "dataset_validation = dataset['validation']"
      ],
      "metadata": {
        "id": "CPcjiDFyLNO3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QPcz2evLfLF",
        "outputId": "abb5f169-90e9-4e38-cb8e-e5ce41a4c7e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec={'idx': TensorSpec(shape=(), dtype=tf.int32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'sentence': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print some of the entries from here\n",
        "\n",
        "for example in dataset_train.take(2):\n",
        "  review, label = example[\"sentence\"], example[\"label\"]\n",
        "  print(\"review\", review)\n",
        "  print(\"label\", label.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_mnb0VyLgdl",
        "outputId": "bcd1167c-c316-436f-9e5b-d49055f9a46b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review tf.Tensor(b'for the uninitiated plays better on video with the sound ', shape=(), dtype=string)\n",
            "label 0\n",
            "review tf.Tensor(b'like a giant commercial for universal studios , where much of the action takes place ', shape=(), dtype=string)\n",
            "label 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#num of insatnces in the dataset_train\n",
        "\n",
        "num_train_examples = len(dataset_train)\n",
        "print(\"training examples are:\", num_train_examples)\n",
        "\n",
        "\n",
        "#validation examples\n",
        "num_validation_examples = len(dataset_validation)\n",
        "print(\"\\n \\n validation examples are:\", num_validation_examples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr_6hOdIMPCw",
        "outputId": "cf1f2beb-8a09-4155-de5b-43b9f6021f71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples are: 67349\n",
            "\n",
            " \n",
            " validation examples are: 872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use 1000 entries fro training  and 800 validation\n",
        "\n",
        "training_reviews = []\n",
        "training_labels = []\n",
        "\n",
        "validation_reviews = []\n",
        "validation_labels = []\n",
        "\n",
        "for item in dataset_train.take(1000):\n",
        "  review, label = item['sentence'], item['label']\n",
        "  training_reviews.append(str(review.numpy()))\n",
        "  training_labels.append(str(label.numpy()))\n",
        "\n",
        "#check how many instances u v got\n",
        "print (\"\\nNumber of training reviews is: \", len(training_reviews))\n",
        "\n",
        "# Get the validation data\n",
        "# there's only about 800 items, so take them all\n",
        "for item in dataset_validation.take(-1):\n",
        "  review, label = item[\"sentence\"], item[\"label\"]\n",
        "  validation_reviews.append(str(review.numpy()))\n",
        "  validation_labels.append(label.numpy())\n",
        "\n",
        "print (\"\\nNumber of validation reviews is: \", len(validation_reviews))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mXl8lk5MYUx",
        "outputId": "0495b37b-2516-428c-8cfc-0d387d255e19"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of training reviews is:  1000\n",
            "\n",
            "Number of validation reviews is:  872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print some of the reviews and labels\n",
        "for i in range(0, 2):\n",
        "  print (training_reviews[i])\n",
        "  print (training_labels[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-MbeEzhPBSG",
        "outputId": "f5f4ff68-68ae-4730-fcc5-4157f1e58f55"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'for the uninitiated plays better on video with the sound '\n",
            "0\n",
            "b'like a giant commercial for universal studios , where much of the action takes place '\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some of the validation reviews and labels\n",
        "for i in range(0, 2):\n",
        "  print (validation_reviews[i])\n",
        "  print (validation_labels[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kDt8QpHPeA3",
        "outputId": "6e2547d9-ec31-4b5b-ef66-952d7839235d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'a valueless kiddie paean to pro basketball underwritten by the nba . '\n",
            "0\n",
            "b\"featuring a dangerously seductive performance from the great daniel auteuil , `` sade '' covers the same period as kaufmann 's `` quills '' with more unsettlingly realistic results . \"\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the words and sequence the sentences"
      ],
      "metadata": {
        "id": "k91ezykrPzlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There's a total of 21224 words in the reviews\n",
        "# but many of them are irrelevant like with, it, of, on.\n",
        "# If we take a subset of the training data, then the vocab\n",
        "# will be smaller.\n",
        "\n",
        "# A reasonable review might have about 50 words or so,\n",
        "# so we can set max_length to 50 (but feel free to change it as you like)\n",
        "\n",
        "vocab_size = 4000\n",
        "embedding_dim = 16\n",
        "max_length = 50\n",
        "trunc_type='post'\n",
        "pad_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_reviews)\n",
        "word_index = tokenizer.word_index\n"
      ],
      "metadata": {
        "id": "4vPI7L-CPiWH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences so that they are all the same length\n",
        "training_sequences = tokenizer.texts_to_sequences(training_reviews)\n",
        "training_padded = pad_sequences(training_sequences,maxlen=max_length,\n",
        "                                truncating=trunc_type, padding=pad_type)\n",
        "\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_reviews)\n",
        "validation_padded = pad_sequences(validation_sequences,maxlen=max_length)\n",
        "\n",
        "# Convert training labels to integers before converting to numpy array\n",
        "training_labels_final = np.array([int(label) for label in training_labels])\n",
        "validation_labels_final = np.array(validation_labels)"
      ],
      "metadata": {
        "id": "kk3R5P5RQEk3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create an embedding model"
      ],
      "metadata": {
        "id": "eHfKjEDzQLmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "dQz4aACYQI2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "\n",
        "num_epochs = 20\n",
        "history = model.fit(training_padded, training_labels_final, epochs=num_epochs,\n",
        "                    validation_data=(validation_padded, validation_labels_final))\n"
      ],
      "metadata": {
        "id": "5R2zxEKwQOFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "metadata": {
        "id": "jeD_vXzJQS3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a function to predict the sentiment of reviews\n",
        "\n",
        "# Write some new reviews\n",
        "\n",
        "review1 = \"\"\"I loved this movie\"\"\"\n",
        "\n",
        "review2 = \"\"\"that was the worst movie I've ever seen\"\"\"\n",
        "\n",
        "review3 = \"\"\"too much violence even for a Bond film\"\"\"\n",
        "\n",
        "review4 = \"\"\"a captivating recounting of a cherished myth\"\"\"\n",
        "\n",
        "new_reviews = [review1, review2, review3, review4]\n"
      ],
      "metadata": {
        "id": "bOci9NYdQ2pI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to prepare the new reviews for use with a model\n",
        "# and then use the model to predict the sentiment of the new reviews\n",
        "\n",
        "def predict_review(model, reviews):\n",
        "  # Create the sequences\n",
        "  padding_type='post'\n",
        "  sample_sequences = tokenizer.texts_to_sequences(reviews)\n",
        "  reviews_padded = pad_sequences(sample_sequences, padding=padding_type,\n",
        "                                 maxlen=max_length)\n",
        "  classes = model.predict(reviews_padded)\n",
        "  for x in range(len(reviews_padded)):\n",
        "    print(reviews[x])\n",
        "    print(classes[x])\n",
        "    print('\\n')\n",
        "\n",
        "predict_review(model, new_reviews)\n"
      ],
      "metadata": {
        "id": "_l-Im45YRPRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to train and show the results of models with different layers"
      ],
      "metadata": {
        "id": "QxY-yqw8RXuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model_and_show_results (model, reviews):\n",
        "  model.summary()\n",
        "  history = model.fit(training_padded, training_labels_final, epochs=num_epochs,\n",
        "                      validation_data=(validation_padded, validation_labels_final))\n",
        "  plot_graphs(history, \"accuracy\")\n",
        "  plot_graphs(history, \"loss\")\n",
        "  predict_review(model, reviews)"
      ],
      "metadata": {
        "id": "3i8JhrxFRQKv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using CNN"
      ],
      "metadata": {
        "id": "aeqs8j--RdKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "model_cnn = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Conv1D(16, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Default learning rate for the Adam optimizer is 0.001\n",
        "# Let's slow down the learning rate by 10.\n",
        "learning_rate = 0.0001\n",
        "model_cnn.compile(loss='binary_crossentropy',\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "fit_model_and_show_results(model_cnn, new_reviews)"
      ],
      "metadata": {
        "id": "0pz7ulaLRZlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using GRU"
      ],
      "metadata": {
        "id": "Htj_rYunRjCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "model_gru = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "learning_rate = 0.00003 # slower than the default learning rate\n",
        "model_gru.compile(loss='binary_crossentropy',\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "fit_model_and_show_results(model_gru, new_reviews)"
      ],
      "metadata": {
        "id": "8Nch6DkuRevf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfQqWa6oRnQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a bidirectional LSTM"
      ],
      "metadata": {
        "id": "ETbSxXXpRqdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "model_bidi_lstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "learning_rate = 0.00003\n",
        "model_bidi_lstm.compile(loss='binary_crossentropy',\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "                        metrics=['accuracy'])\n",
        "fit_model_and_show_results(model_bidi_lstm, new_reviews)"
      ],
      "metadata": {
        "id": "i_ydq-vJRsOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using multiple bidirectional LSTMS"
      ],
      "metadata": {
        "id": "CDKG9dIzRxX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "model_multiple_bidi_lstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,\n",
        "                                                       return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "learning_rate = 0.0003\n",
        "model_multiple_bidi_lstm.compile(loss='binary_crossentropy',\n",
        "                                 optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "                                 metrics=['accuracy'])\n",
        "fit_model_and_show_results(model_multiple_bidi_lstm, new_reviews)"
      ],
      "metadata": {
        "id": "ed9ErHSfR4rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write some new reviews\n",
        "\n",
        "review1 = \"\"\"I loved this movie\"\"\"\n",
        "\n",
        "review2 = \"\"\"that was the worst movie I've ever seen\"\"\"\n",
        "\n",
        "review3 = \"\"\"too much violence even for a Bond film\"\"\"\n",
        "\n",
        "review4 = \"\"\"a captivating recounting of a cherished myth\"\"\"\n",
        "\n",
        "review5 = \"\"\"I saw this movie yesterday and I was feeling low to start with,\n",
        " but it was such a wonderful movie that it lifted my spirits and brightened\n",
        " my day, you can\\'t go wrong with a movie with Whoopi Goldberg in it.\"\"\"\n",
        "\n",
        "review6 = \"\"\"I don\\'t understand why it received an oscar recommendation\n",
        " for best movie, it was long and boring\"\"\"\n",
        "\n",
        "review7 = \"\"\"the scenery was magnificent, the CGI of the dogs was so realistic I\n",
        " thought they were played by real dogs even though they talked!\"\"\"\n",
        "\n",
        "review8 = \"\"\"The ending was so sad and yet so uplifting at the same time.\n",
        " I'm looking for an excuse to see it again\"\"\"\n",
        "\n",
        "review9 = \"\"\"I had expected so much more from a movie made by the director\n",
        " who made my most favorite movie ever, I was very disappointed in the tedious\n",
        " story\"\"\"\n",
        "\n",
        "review10 = \"I wish I could watch this movie every day for the rest of my life\"\n",
        "\n",
        "more_reviews = [review1, review2, review3, review4, review5, review6, review7,\n",
        "               review8, review9, review10]\n"
      ],
      "metadata": {
        "id": "uDGMRNZYR-L2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"============================\\n\",\"Embeddings only:\\n\", \"============================\")\n",
        "predict_review(model, more_reviews)"
      ],
      "metadata": {
        "id": "k1Azc2GPSA0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"============================\\n\",\"With CNN\\n\", \"============================\")\n",
        "predict_review(model_cnn, more_reviews)"
      ],
      "metadata": {
        "id": "gr0VYuHrSCsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===========================\\n\",\"With bidirectional GRU\\n\", \"============================\")\n",
        "predict_review(model_gru, more_reviews)"
      ],
      "metadata": {
        "id": "46T1KAAySDlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===========================\\n\", \"With a single bidirectional LSTM:\\n\", \"===========================\")\n",
        "predict_review(model_bidi_lstm, more_reviews)"
      ],
      "metadata": {
        "id": "f64Fw0yCSHMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===========================\\n\", \"With multiple bidirectional LSTM:\\n\", \"==========================\")\n",
        "predict_review(model_multiple_bidi_lstm, more_reviews)"
      ],
      "metadata": {
        "id": "g6fW2g8lSJGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36Gnd3qmUAHn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}